In all example, we want to sort this list of numbers in ascending order:

#+BEGIN_SRC 
[3,2,87,45,43,77,12,99,34,75,23,74,105,950,450,346,210,323]
#+END_SRC

** Bubble sort
If we think visually, this is just ~bubbling~ up elements (starting from index 0) to the right. After =i= iterations, the
last =i= elements in the array are ordered. Note that in bubble sort, the maximums are bubbled to the unsorted section (right).

#+BEGIN_SRC C++ :exports both
#include <array>
#include <iostream>

namespace my {

/// @brief Swaps array[firstIndex] with array[secondIndex]
template <size_t SIZE>
void swap(std::array<int, SIZE>& array, size_t firstIndex, size_t secondIndex);

/// @brief Performs bubble sort on array
template <size_t SIZE> void bubbleSort(std::array<int, SIZE>& array);

/// @brief Prints a given array
template <size_t SIZE>
void printArrayToStdOut(const std::array<int, SIZE>& array);
}

int main() {
    using namespace my;

    std::array<int, 18> array = {3,  2,  87, 45,  43,  77,  12,  99,  34,
                                 75, 23, 74, 105, 950, 450, 346, 210, 323};

    printArrayToStdOut(array);

    bubbleSort(array);

    printArrayToStdOut(array);

    return 0;
}

template <size_t SIZE> void my::bubbleSort(std::array<int, SIZE>& array) {
    for (size_t i = 0; i < SIZE - 1; ++i) {
        for (size_t j = 0; j < SIZE - 1 - i; ++j) {
            if (array[j] > array[j + 1]) {
                swap(array, j, j + 1);
            }
        }
    }
}

template <size_t SIZE>
void my::swap(std::array<int, SIZE>& array, size_t firstIndex,
              size_t secondIndex) {
    const int firstIndexOriginalValue = array[firstIndex];
    array[firstIndex] = array[secondIndex];
    array[secondIndex] = firstIndexOriginalValue;
}

template <size_t SIZE>
void my::printArrayToStdOut(const std::array<int, SIZE>& array) {
    std::cout << "[ ";
    for (const auto& element : array) {
        std::cout << element << " ";
    }
    std::cout << "] " << std::endl;
}

#+END_SRC

#+RESULTS:
| [ | 3 | 2 | 87 | 45 | 43 | 77 | 12 | 99 | 34 | 75 | 23 | 74 | 105 | 950 | 450 | 346 | 210 | 323 | ] |
| [ | 2 | 3 | 12 | 23 | 34 | 43 | 45 | 74 | 75 | 77 | 87 | 99 | 105 | 210 | 323 | 346 | 450 | 950 | ] |

*** Analysis
In the worst case, time complexity is $O(n^2)$ where =n= is the number of elements in the array or size of the array. Average is the same. Best is actually $O(n)$ but for that we have to modify the
above algorithm to cache whether we made a swap during an iteration. If the list is already sorted, a linear scan would result in
no swaps at which point we'll end the algorithm. 
In terms of memory, this algorithm is $O(1)$.

** Insertion sort
Similar to bubble sort.
If we think visually, this is just ~bubbling~ up elements (starting from index 1) to the left. After =i= iterations, the
first =i= elements in the array are ordered. Note that in insertion sort, the minimums are bubbled to the sort section in the left.
Note that both bubble sort and insertion sort are =inplace= algorithms i.e. they modify the array while it's being sorted. At
the end, the input array /is/ is the sorted array.
#+BEGIN_SRC C++ :exports both
#include <array>
#include <iostream>

namespace my {

/// @brief Swaps array[firstIndex] with array[secondIndex]
template <size_t SIZE>
void swap(std::array<int, SIZE>& array, size_t firstIndex, size_t secondIndex);

/// @brief Performs insertion sort on array
template <size_t SIZE> void insertionSort(std::array<int, SIZE>& array);

/// @brief Prints a given array
template <size_t SIZE>
void printArrayToStdOut(const std::array<int, SIZE>& array);
}

int main() {
    using namespace my;

    std::array<int, 18> array = {3,  2,  87, 45,  43,  77,  12,  99,  34,
                                 75, 23, 74, 105, 950, 450, 346, 210, 323};

    printArrayToStdOut(array);

    insertionSort(array);

    printArrayToStdOut(array);

    return 0;
}

template <size_t SIZE> void my::insertionSort(std::array<int, SIZE>& array) {
    for (int i = 1; i <= SIZE - 1; ++i) {
        const int key = array[i];
        for (int j = i - 1; j >= 0; --j) {
            // if at any point when going left, we find an element that is
            // smaller than the
            // key, we can safely break. This is because we know that the left
            // section is sorted
            // and if an element is already smaller than the key, than we don't
            // need to go any more left.
            if (array[j] <= key) {
                break;
            }
            if (array[j] > array[j + 1]) {
                swap(array, j, j + 1);
            }
        }
    }
}

template <size_t SIZE>
void my::swap(std::array<int, SIZE>& array, size_t firstIndex,
              size_t secondIndex) {
    // another way of swapping without using temp
    // don't like this too much because of potential integer overflows :)
    array[firstIndex] = array[firstIndex] + array[secondIndex];
    array[secondIndex] = array[firstIndex] - array[secondIndex];
    array[firstIndex] = array[firstIndex] - array[secondIndex];
}

template <size_t SIZE>
void my::printArrayToStdOut(const std::array<int, SIZE>& array) {
    std::cout << "[ ";
    for (const auto& element : array) {
        std::cout << element << " ";
    }
    std::cout << "] " << std::endl;
}
#+END_SRC

#+RESULTS:
| [ | 3 | 2 | 87 | 45 | 43 | 77 | 12 | 99 | 34 | 75 | 23 | 74 | 105 | 950 | 450 | 346 | 210 | 323 | ] |
| [ | 2 | 3 | 12 | 23 | 34 | 43 | 45 | 74 | 75 | 77 | 87 | 99 | 105 | 210 | 323 | 346 | 450 | 950 | ] |

*** Analysis
This is again $O(n^2)$ in time. Average is the same. In the best case though, this will be $O(n)$. Memory is $O(1)$.
Note that we can make $O(nlogn)$ comparisons instead of $O(n^2)$ by using binary search at every iteration. Swaps are
still $O(n^2)$ though, sadly.
** Merge sort
Typical divide and conquer algorithm which can be solved recursively. The beauty of recursion is that the code
is self documenting:

#+BEGIN_SRC C++ :exports both
#include <algorithm>
#include <iostream>
#include <vector>

namespace my {

/// @brief Performs merge sort on array
std::vector<int> mergeSort(std::vector<int>& array);

/// @brief Merge two sorted arrays
std::vector<int> mergeSortedArrays(std::vector<int>& firstSortedArray,
                                   std::vector<int>& secondSortedArray);

/// @brief Prints a given array
void printArrayToStdOut(const std::vector<int>& array);
}

int main() {
    using namespace my;

    // for this example, array size has to be of the form 2^n where n a
    // non-negative integer
    std::vector<int> array = {3,  2,  87, 45, 43,  77,  12,  99,
                              34, 75, 23, 74, 105, 950, 450, 346};

    printArrayToStdOut(array);

    printArrayToStdOut(mergeSort(array));

    return 0;
}

std::vector<int> my::mergeSort(std::vector<int>& array) {
    const size_t arraySize = array.size();
    if (arraySize <= 1)
        return array;

    const bool isArraySizeEven = (arraySize % 2 == 0);
    if (!isArraySizeEven) {
        std::cout << "Only even sized arrays supported for now" << std::endl;
        return array;
    }

    std::vector<int> leftArray;
    std::vector<int> rightArray;

    for (size_t vectorIndex = 0; vectorIndex < array.size(); ++vectorIndex) {
        if (vectorIndex <= array.size() / 2 - 1) {
            leftArray.push_back(array[vectorIndex]);
        } else {
            rightArray.push_back(array[vectorIndex]);
        }
    }

    leftArray = mergeSort(leftArray);
    rightArray = mergeSort(rightArray);

    return mergeSortedArrays(leftArray, rightArray);
}

std::vector<int> my::mergeSortedArrays(std::vector<int>& firstSortedArray,
                                       std::vector<int>& secondSortedArray) {
    // no need to do anything if arrays are empty
    if (firstSortedArray.empty() && secondSortedArray.empty())
        return firstSortedArray;
    if (firstSortedArray.empty())
        return secondSortedArray;
    if (secondSortedArray.empty())
        return firstSortedArray;

    // ensure firstSortedArray is the same size as secondSortedArray
    if (firstSortedArray.size() != secondSortedArray.size()) {
        // Until I setup asserts...
        std::cout << "Arrays must be the same size" << std::endl;
        return firstSortedArray;
    }

    size_t firstSortedArrayPtrIndex = 0;
    size_t secondSortedArrayPtrIndex = 0;
    size_t mergedArrayPtrIndex = 0;

    std::vector<int> mergedArray;
    while (mergedArrayPtrIndex <= 2 * firstSortedArray.size() - 1) {
        const bool allFirstSortedArrayValuesUsed =
            firstSortedArrayPtrIndex > firstSortedArray.size() - 1;
        const bool allSecondSortedArrayValuesUsed =
            secondSortedArrayPtrIndex > secondSortedArray.size() - 1;
        const bool useFirstSortedArrayValue =
            !allFirstSortedArrayValuesUsed &&
            (allSecondSortedArrayValuesUsed ||
             (firstSortedArray[firstSortedArrayPtrIndex] <
              secondSortedArray[secondSortedArrayPtrIndex]));
        if (useFirstSortedArrayValue) {
            mergedArray.push_back(firstSortedArray[firstSortedArrayPtrIndex]);
            ++firstSortedArrayPtrIndex;
        } else {
            mergedArray.push_back(secondSortedArray[secondSortedArrayPtrIndex]);
            ++secondSortedArrayPtrIndex;
        }

        ++mergedArrayPtrIndex;
    }

    return mergedArray;
}

void my::printArrayToStdOut(const std::vector<int>& array) {
    std::cout << "[ ";
    for (const auto& element : array) {
        std::cout << element << " ";
    }
    std::cout << "] " << std::endl;
}

#+END_SRC

#+RESULTS:
| [ | 3 | 2 | 87 | 45 | 43 | 77 | 12 | 99 | 34 | 75 | 23 | 74 | 105 | 950 | 450 | 346 | ] |
| [ | 2 | 3 | 12 | 23 | 34 | 43 | 45 | 74 | 75 | 77 | 87 | 99 | 105 | 346 | 450 | 950 | ] |

*** Analysis
Best, average and worst time is sigma(nlogn). Memory in the worst case is O(n). Note that we sometimes use
sigma for best, theta for average and O for worst case complexities.

*** Note
A lot of code here is not production quality. This is just quick brainstorming to get things working. For instance,
clearly using =std::vector= as an /array/ is a bad idea because of the cost of lookups. But it gets the point across as an example.
** Quick sort
Copied from [[https://www.khanacademy.org/computing/computer-science/algorithms/quick-sort/a/overview-of-quicksort][these notes]]:
Like merge sort, quicksort uses divide-and-conquer, and so it's a recursive algorithm. The way that quicksort uses divide-and-conquer is a little different from how merge sort does. In merge sort, the divide step does hardly anything, and all the real work happens in the combine step. Quicksort is the opposite: all the real work happens in the divide step. In fact, the combine step in quicksort does absolutely nothing.
Quicksort has a couple of other differences from merge sort. Quicksort works /in place/. And its worst-case running time is as bad as selection sort's and insertion sort's: O(n^2). But its average-case running time is as good as merge sort's: O(nlogn). So why think about quicksort when merge sort is at least as good? That's because the constant factor hidden in the big-O notation for quicksort is quite good. In practice, quicksort outperforms merge sort, and it significantly outperforms selection sort and insertion sort.

Here is how quicksort uses divide-and-conquer. As with merge sort, think of sorting a subarray array[p..r], where initially the subarray is array[0..n-1].
1. Divide by choosing any element in the subarray array[p..r]. Call this element the pivot. Rearrange the elements in array[p..r] so that all other elements in array[p..r] that are less than or equal to the pivot are to its left and all elements in array[p..r] are to the pivot's right. We call this procedure partitioning. At this point, it doesn't matter what order the elements to the left of the pivot are in relative to each other, and the same holds for the elements to the right of the pivot. We just care that each element is somewhere on the correct side of the pivot. As a matter of practice, we'll always choose the rightmost element in the subarray, array[r], as the pivot. So, for example, if the subarray consists of [9, 7, 5, 11, 12, 2, 14, 3, 10, 6], then we choose 6 as the pivot. After partitioning, the subarray might look like [5, 2, 3, 6, 12, 7, 14, 9, 10, 11]. Let q be the index of where the pivot ends up.
2. Conquer by recursively sorting the subarrays array[p..q-1] (all elements to the left of the pivot, which must be less than or equal to the pivot) and array[q+1..r] (all elements to the right of the pivot, which must be greater than the pivot).
3. Combine by doing nothing. Once the conquer step recursively sorts, we are done. Why? All elements to the left of the pivot, in array[p..q-1], are less than or equal to the pivot and are sorted, and all elements to the right of the pivot, in array[q+1..r], are greater than the pivot and are sorted. The elements in array[p..r] can't help but be sorted!

Think about our example. After recursively sorting the subarrays to the left and right of the pivot, the subarray to the left of the pivot is [2, 3, 5], and the subarray to the right of the pivot is [7, 9, 10, 11, 12, 14]. So the subarray has [2, 3, 5], followed by 6, followed by [7, 9, 10, 11, 12, 14]. The subarray is sorted.

Let's go back to the conquer step and walk through the recursive sorting of the subarrays. After the first partition, we have have subarrays of [5, 2, 3] and [12, 7, 14, 9, 10, 11], with 6 as the pivot.
To sort the subarray [5, 2, 3], we choose 3 as the pivot. After partitioning, we have [2, 3, 5]. The subarray [2], to the left of the pivot, is a base case when we recurse, as is the subarray [5], to the right of the pivot.
To sort the subarray [12, 7, 14, 9, 10, 11], we choose 11 as the pivot, resulting in [7, 9, 10] to the left of the pivot and [14, 12] to the right. After these subarrays are sorted, we have [7, 9, 10], followed by 11, followed by [12, 14].

The code looks like follows (below). Note that pivot selection is important and there are many ways to pick one. Here, we'll just
pick the first element in the subarray as the pivot.

#+BEGIN_SRC C++ :exports both
#include <iostream>
#include <string>
#include <algorithm>
#include <vector>

using namespace std;

void print(const vector<int>& vec) {
    for (auto e : vec)
        cout << e << " ";
    cout << endl;
}

void swap(vector<int>& vec, int i, int j) {
    int t = vec[i];
    vec[i] = vec[j];
    vec[j] = t;
}

/// parition around pivot and return pivot index
int partition(vector<int>& vec, int left, int right) {
    /// let's pick the first element as the pivot
    int pivot = vec[left];
    /// "i" is just the marker we use (marker approach / pointer approach)
    int i = left + 1;
    /// first, rearrange the array from A[left + 1, right] such
    /// that elements less than pivot are on one side and greater on the other
    /// note that pivot itself is A[left]
    for (int j = left + 1; j <= right; ++j) {
        if (vec[j] < pivot) {
            swap(vec, i, j);
            i++;
        }
    }
    /// finally, put the pivot in its proper place
    swap(vec, left, i - 1);
    return i - 1;
}

void quick_sort(vector<int>& vec, int left, int right) {
    if (right - left <= 0)
        return;
    int pivot_idx = partition(vec, left, right);
    quick_sort(vec, left, pivot_idx - 1);
    quick_sort(vec, pivot_idx + 1, right);
}

int main() {
    vector<int> A = {9, 9, 7, 5, 11, 7, 12, 10, 3, 6, 2, 14, 2, 3, 10, 6};
    quick_sort(A, 0, A.size() - 1);
    print(A);
    return 0;
}
#+END_SRC

This outputs: 2 2 3 3 5 6 6 7 7 9 9 10 10 11 12 14

*** Analysis
The worst-case time complexity is O(n^2) since for every subarray (recursive function), we traverse the subarray again for partitioning.
Paritioning itself is O(right - left). The space complexity is O(1) since this is an in place algorithm.

We can improve the time complexity of this algorithm using randomization, specifically by randomly picking the pivot using the following
parition function as an example:

#+BEGIN_SRC C++ :exports both
int rand_partition (int A[ ], int start, int end) {
     // chooses position of pivot randomly by using rand() function.
     int random = start + rand( )%(end-start +1 );
     swap(A[random], A[start]);        // swap pivot with 1st element.
     return partition(A, start, end);  // call the default partition function
}
#+END_SRC

Now, the average time complexity becomes O(nlog(n)).
** Heap sort
** BST sort
** Counting sort
** Radix sort
